import os
import json
import time
import requests
import threading
import argparse
import sys
import math
import hashlib
from filechunkio import FileChunkIO
from concurrent.futures import ThreadPoolExecutor
from ks3.connection import Connection
from ks3.multipart import PartInfo
# TODO:æ‰“åŒ…æ”¾å¼€
from robot_data_uploader import config
# NOTE:å¼€å‘è°ƒè¯•
# import config
from tqdm import tqdm
from io import BytesIO
from colorama import init, Fore, Style
import pyfiglet
from pyfiglet import Figlet
from dataclasses import dataclass
from typing import Optional, List, Dict, Any

# åˆå§‹åŒ–é¢œè‰²è¾“å‡º
init(autoreset=True)

__version__ = "1.0.0"
__author__ = "DataPlatform"
# __license__ = "Apache-2.0"
__repo__ = "https://gitee.com/baai-data/baai-eai-datasuite.git"
__description__ = "æœºå™¨æ•°æ®ä¸Šä¼ å·¥å…·,æ”¯æŒæ–­ç‚¹ç»­ä¼ ã€è¿›åº¦æ˜¾ç¤ºå’Œæ–‡ä»¶è¿‡æ»¤"
__help__ = "å¦‚é‡é—®é¢˜è¯·åŠæ—¶æŠ¥å‘Šåé¦ˆ: dataplatform@baai.ac.cn"

# è¿”å›ç å®šä¹‰
class ResultCode:
    """è¿”å›ç å¸¸é‡å®šä¹‰"""
    SUCCESS = 200          # æ“ä½œæˆåŠŸ
    FAIL = 500            # æ“ä½œå¤±è´¥
    PARAM_ERROR = 400     # å‚æ•°é”™è¯¯
    NOT_FOUND = 404       # èµ„æºæœªæ‰¾åˆ°
    UNAUTHORIZED = 401     # æœªæˆæƒ
    FORBIDDEN = 403        # ç¦æ­¢è®¿é—®
    CONFLICT = 409         # èµ„æºå†²çª
    VALIDATION_ERROR = 422 # éªŒè¯é”™è¯¯
    SYSTEM_ERROR = 500     # ç³»ç»Ÿé”™è¯¯
    UPLOAD_CANCELLED = 499 # ä¸Šä¼ è¢«å–æ¶ˆ

@dataclass
class UploadResult:
    """ä¸Šä¼ ç»“æœæ•°æ®ç±»"""
    code: int                    # è¿”å›ç 
    msg: str                     # è¿”å›æ¶ˆæ¯
    data: Optional[Dict[str, Any]] = None  # è¿”å›æ•°æ®
    
    def is_success(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦æˆåŠŸ"""
        return self.code == ResultCode.SUCCESS
    
    def is_failed(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¤±è´¥"""
        return self.code != ResultCode.SUCCESS
    
    @classmethod
    def success(cls, msg: str = "æ“ä½œæˆåŠŸ", data: Optional[Dict[str, Any]] = None) -> 'UploadResult':
        """åˆ›å»ºæˆåŠŸç»“æœ"""
        return cls(code=ResultCode.SUCCESS, msg=msg, data=data)
    
    @classmethod
    def fail(cls, code: int = ResultCode.FAIL, msg: str = "æ“ä½œå¤±è´¥", data: Optional[Dict[str, Any]] = None) -> 'UploadResult':
        """åˆ›å»ºå¤±è´¥ç»“æœ"""
        return cls(code=code, msg=msg, data=data)
    
    @classmethod
    def param_error(cls, msg: str = "å‚æ•°é”™è¯¯", data: Optional[Dict[str, Any]] = None) -> 'UploadResult':
        """åˆ›å»ºå‚æ•°é”™è¯¯ç»“æœ"""
        return cls(code=ResultCode.PARAM_ERROR, msg=msg, data=data)
    
    @classmethod
    def not_found(cls, msg: str = "èµ„æºæœªæ‰¾åˆ°", data: Optional[Dict[str, Any]] = None) -> 'UploadResult':
        """åˆ›å»ºèµ„æºæœªæ‰¾åˆ°ç»“æœ"""
        return cls(code=ResultCode.NOT_FOUND, msg=msg, data=data)
    
    @classmethod
    def conflict(cls, msg: str = "èµ„æºå†²çª", data: Optional[Dict[str, Any]] = None) -> 'UploadResult':
        """åˆ›å»ºèµ„æºå†²çªç»“æœ"""
        return cls(code=ResultCode.CONFLICT, msg=msg, data=data)
    
    @classmethod
    def cancelled(cls, msg: str = "æ“ä½œè¢«å–æ¶ˆ", data: Optional[Dict[str, Any]] = None) -> 'UploadResult':
        """åˆ›å»ºæ“ä½œè¢«å–æ¶ˆç»“æœ"""
        return cls(code=ResultCode.UPLOAD_CANCELLED, msg=msg, data=data)

# ä»¥ä¸‹æ˜¯åŸclient/uploader.pyçš„å…¶ä½™å†…å®¹ï¼Œä¿æŒä¸å˜
def print_header():
    """æ˜¾ç¤ºå·¥å…·å¤´ä¿¡æ¯"""
    f = Figlet(font='slant')
    print(Fore.CYAN + f.renderText('Robot Data Uploader'))
    
    print(f"{Fore.YELLOW}â– Version{Style.RESET_ALL}: {__version__}")
    print(f"{Fore.YELLOW}â– Author{Style.RESET_ALL}:  {__author__}")
    # print(f"{Fore.YELLOW}â– License{Style.RESET_ALL}: {__license__}")
    print(f"{Fore.YELLOW}â– Source{Style.RESET_ALL}:  {__repo__}")
    print("\n" + "-" * 80)

def show_banner():
    """æ˜¾ç¤ºç¨‹åºæ¨ªå¹…"""
    banner = pyfiglet.figlet_format("BAAI Robot Data Uploader", font="slant")
    print(f"{Fore.CYAN}{banner}")
    print(f"{Fore.CYAN}{'=' * 60}")
    print(f"{Fore.YELLOW}â– Description{Style.RESET_ALL}: {__description__}")
    print(f"{Fore.YELLOW}â– Version{Style.RESET_ALL}: {__version__}")
    print(f"{Fore.YELLOW}â– Author{Style.RESET_ALL}:  {__author__}")
    print(f"{Fore.YELLOW}â– Help{Style.RESET_ALL}:  {__help__}")

    # print(f"{Fore.YELLOW}ç›®æ ‡å­˜å‚¨: {config.BUCKET_NAME}")
    print(f"{Fore.CYAN}{'=' * 60}\n")

from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich import box

console = Console()

def show_menu(current_filters, auth_method, max_workers):
    # èœå•é¢æ¿
    panel = Panel(
        "[bold cyan]â‹™ æ™ºæºæœºå™¨äººæ•°æ®ä¼ è¾“ç®¡ç†å™¨ v1.0.0[/]\n[dim]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[/]",
        title="[bold yellow]âˆ ä¸»èœå•[/]",
        subtitle="[dim italic]â†‘â†“ é€‰æ‹©ï¼Œâ†© ç¡®è®¤[/]",
        border_style="bright_blue"
    )
    console.print(panel)

    # é€‰é¡¹è¡¨æ ¼
    table = Table.grid(padding=(0, 2))
    table.add_column(style="bold cyan", width=2)  # åºå·åˆ—
    table.add_column(style="bold white")          # åŠŸèƒ½åˆ—
    table.add_column(style="dim yellow")          # çŠ¶æ€åˆ—
    # current_filters = [ "*.txt", "*.csv", "*.json", "*.dat" , "*.tar", "*.png"]
    # auth_method = "STS"
    table.add_row("1", "ğŸ“¤ ä¸Šä¼ å•ä¸ªæ–‡ä»¶", "[è¯·é€‰æ‹©å•ä¸ªæ–‡ä»¶]")
    table.add_row("2", "ğŸ“‚ ä¸Šä¼ ç›®å½•", "[é€’å½’ä¸Šä¼ æ‰€æœ‰åŒ¹é…æ–‡ä»¶]")
    table.add_row("3", "ğŸ›¡ï¸ è®¾ç½®æ–‡ä»¶è¿‡æ»¤å™¨", f"[å½“å‰: [bold green]{current_filters}[/]]")
    table.add_row("4", "ğŸ”‘ åˆ‡æ¢è®¤è¯æ–¹å¼", f"[å½“å‰: [bold magenta]{auth_method}[/]]")
    table.add_row("5", "âš™ï¸ è®¾ç½®ä¸Šä¼ çº¿ç¨‹æ•°", f"[å½“å‰: [bold blue]{max_workers}[/]]")
    table.add_row("6", "â›” é€€å‡ºç³»ç»Ÿ", "[bold red]å®‰å…¨å…³é—­è¿æ¥[/]")

    console.print(table, justify="left")
    # åŠ¨æ€æç¤º
    # console.print(
    #     "[dim]â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„[/]\n"
    #     "[bold]å¿«æ·æ“ä½œ:[/] æ”¯æŒä½¿ç”¨å‘½ä»¤è¡Œ, [cyan]-h[/]å‚æ•°å¸®åŠ©"
    # )
    
# æ˜¯å¦å­˜åœ¨ks3ä¸­çš„è·¯å¾„åˆ†éš”ç¬¦â€œ/â€
def has_any_path_separator(path_str):
    return '/' in path_str[1:-1]  # æ£€æŸ¥ä¸­é—´æ˜¯å¦åŒ…å«`/`
    

class BaaiRobotDataUploader:
    
    def __init__(self, use_direct_auth=False):
        # æ•°é‡‡å¹³å°ç›¸å…³å‚æ•°
        self.eai_token = None
        self.eai_task_id = None
        self.eai_upload_task_id = None
        # ä¸Šä¼ å·¥å…·ç›¸å…³å‚æ•°
        self.sts_token = None
        self.connection = None
        self.resume_dir = ".upload_resume"
        self.file_filters = ["*.*"]  # "*.txt", "*.csv", "*.json", "*.dat" , "*.tar", "*.png" # é»˜è®¤æ–‡ä»¶è¿‡æ»¤å™¨
        self.use_direct_auth = use_direct_auth
        self.max_worker = 4
        
        # åˆ›å»ºæ–­ç‚¹ç»­ä¼ ç›®å½•
        if not os.path.exists(self.resume_dir):
            os.makedirs(self.resume_dir)
            
    
    def set_sts_token(self, sts_token):
        self.sts_token = sts_token
    
    def set_eai_token(self, eai_token):
        self.eai_token = eai_token
        
    def set_max_worker(self, max_worker):
        self.max_worker = max_worker
        
        
    def set_file_filters(self, filters):
        """è®¾ç½®æ–‡ä»¶è¿‡æ»¤å™¨"""
        self.file_filters = filters
    
    def _is_file_allowed(self, filename):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç¬¦åˆè¿‡æ»¤è§„åˆ™"""
        import fnmatch
        # å¦‚æœè¿‡æ»¤å™¨åŒ…å«"*.*"ï¼Œè¡¨ç¤ºå…è®¸æ‰€æœ‰æ–‡ä»¶
        if "*.*" in self.file_filters:
            return True
        # å¦åˆ™æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä¸€è¿‡æ»¤è§„åˆ™
        return any(fnmatch.fnmatch(filename.lower(), pattern.lower()) 
                  for pattern in self.file_filters)
    
    def _get_file_md5(self, file_path):
        """è®¡ç®—æ–‡ä»¶MD5"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def _get_file_sha256(self, file_path):
        """è®¡ç®—æ–‡ä»¶SHA256"""
        hash_sha256 = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_sha256.update(chunk)
        return hash_sha256.hexdigest()
    
    def _verify_file_content(self, local_file_path, remote_key, verify_method="md5"):
        """éªŒè¯æœ¬åœ°æ–‡ä»¶å’Œè¿œç¨‹æ–‡ä»¶å†…å®¹æ˜¯å¦ä¸€è‡´
        
        Args:
            local_file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            remote_key: è¿œç¨‹æ–‡ä»¶å¯¹è±¡
            verify_method: éªŒè¯æ–¹æ³• ("size", "md5", "sha256", "strict")
            
        Returns:
            bool: å†…å®¹æ˜¯å¦ä¸€è‡´
        """
        try:
            # è·å–æœ¬åœ°æ–‡ä»¶ä¿¡æ¯
            local_size = os.path.getsize(local_file_path)
            
            # è·å–è¿œç¨‹æ–‡ä»¶ä¿¡æ¯
            remote_size = remote_key.size
            
            # é¦–å…ˆæ¯”è¾ƒæ–‡ä»¶å¤§å°ï¼ˆæ‰€æœ‰éªŒè¯æ–¹æ³•éƒ½éœ€è¦ï¼‰
            if local_size != remote_size:
                print(f"{Fore.BLUE}æ–‡ä»¶å¤§å°ä¸ä¸€è‡´: æœ¬åœ°={local_size}, è¿œç¨‹={remote_size}")
                return False
            
            # å¦‚æœåªæ˜¯å¤§å°éªŒè¯ï¼Œåˆ°è¿™é‡Œå°±ç»“æŸäº†
            if verify_method == "size":
                print(f"{Fore.GREEN}æ–‡ä»¶å¤§å°éªŒè¯é€šè¿‡: {local_size}")
                return True
            
            # è·å–è¿œç¨‹æ–‡ä»¶çš„ETagï¼ˆé€šå¸¸æ˜¯MD5ï¼‰
            remote_etag = remote_key.etag.strip('"') if remote_key.etag else None
            
            if verify_method == "md5":
                # MD5éªŒè¯
                local_md5 = self._get_file_md5(local_file_path)
                if not remote_etag:
                    print(f"{Fore.YELLOW}è¿œç¨‹æ–‡ä»¶ç¼ºå°‘ETagï¼Œæ— æ³•è¿›è¡ŒMD5éªŒè¯")
                    return False
                
                if local_md5 != remote_etag:
                    print(f"{Fore.BLUE}æ–‡ä»¶MD5ä¸ä¸€è‡´: æœ¬åœ°={local_md5}, è¿œç¨‹={remote_etag}")
                    return False
                
                print(f"{Fore.GREEN}æ–‡ä»¶MD5éªŒè¯é€šè¿‡: {local_md5}")
                return True
                
            elif verify_method == "sha256":
                # SHA256éªŒè¯ï¼ˆéœ€è¦ä»è¿œç¨‹æ–‡ä»¶ä¸‹è½½è®¡ç®—ï¼‰
                local_sha256 = self._get_file_sha256(local_file_path)
                
                # ä»è¿œç¨‹æ–‡ä»¶è®¡ç®—SHA256
                try:
                    remote_content = remote_key.get_contents_as_string()
                    remote_sha256 = hashlib.sha256(remote_content).hexdigest()
                    
                    if local_sha256 != remote_sha256:
                        print(f"{Fore.BLUE}æ–‡ä»¶SHA256ä¸ä¸€è‡´: æœ¬åœ°={local_sha256}, è¿œç¨‹={remote_sha256}")
                        return False
                    
                    print(f"{Fore.GREEN}æ–‡ä»¶SHA256éªŒè¯é€šè¿‡: {local_sha256}")
                    return True
                except Exception as e:
                    print(f"{Fore.YELLOW}æ— æ³•è·å–è¿œç¨‹æ–‡ä»¶å†…å®¹è¿›è¡ŒSHA256éªŒè¯: {str(e)}")
                    return False
                    
            elif verify_method == "strict":
                # ä¸¥æ ¼éªŒè¯ï¼šåŒæ—¶éªŒè¯MD5å’ŒSHA256
                local_md5 = self._get_file_md5(local_file_path)
                local_sha256 = self._get_file_sha256(local_file_path)
                
                # éªŒè¯MD5
                if not remote_etag or local_md5 != remote_etag:
                    print(f"{Fore.BLUE}æ–‡ä»¶MD5éªŒè¯å¤±è´¥: æœ¬åœ°={local_md5}, è¿œç¨‹={remote_etag}")
                    return False
                
                # éªŒè¯SHA256
                try:
                    remote_content = remote_key.get_contents_as_string()
                    remote_sha256 = hashlib.sha256(remote_content).hexdigest()
                    
                    if local_sha256 != remote_sha256:
                        print(f"{Fore.BLUE}æ–‡ä»¶SHA256éªŒè¯å¤±è´¥: æœ¬åœ°={local_sha256}, è¿œç¨‹={remote_sha256}")
                        return False
                    
                    print(f"{Fore.GREEN}æ–‡ä»¶ä¸¥æ ¼éªŒè¯é€šè¿‡: MD5={local_md5}, SHA256={local_sha256}")
                    return True
                except Exception as e:
                    print(f"{Fore.YELLOW}æ— æ³•è¿›è¡Œä¸¥æ ¼éªŒè¯: {str(e)}")
                    return False
            
            else:
                print(f"{Fore.YELLOW}ä¸æ”¯æŒçš„éªŒè¯æ–¹æ³•: {verify_method}")
                return False
                
        except Exception as e:
            print(f"{Fore.YELLOW}æ–‡ä»¶å†…å®¹éªŒè¯å¤±è´¥: {str(e)}")
            # éªŒè¯å¤±è´¥æ—¶ï¼Œä¸ºäº†å®‰å…¨èµ·è§ï¼Œä¸è·³è¿‡ä¸Šä¼ 
            return False
    
    def _get_resume_info(self, file_path):
        """è·å–æ–­ç‚¹ç»­ä¼ ä¿¡æ¯"""
        resume_file = os.path.join(
            self.resume_dir, 
            f"{self._get_file_md5(file_path)}.json"
        )
        if os.path.exists(resume_file):
            with open(resume_file, 'r') as f:
                return json.load(f)
        return None
    
    def _save_resume_info(self, file_path, info):
        """ä¿å­˜æ–­ç‚¹ç»­ä¼ ä¿¡æ¯"""
        resume_file = os.path.join(
            self.resume_dir,
            f"{self._get_file_md5(file_path)}.json"
        )
        with open(resume_file, 'w') as f:
            json.dump(info, f)
    
    def _delete_resume_info(self, file_path):
        """åˆ é™¤æ–­ç‚¹ç»­ä¼ ä¿¡æ¯"""
        resume_file = os.path.join(
            self.resume_dir,
            f"{self._get_file_md5(file_path)}.json"
        )
        if os.path.exists(resume_file):
            os.remove(resume_file)
    
    def get_connection(self):
        """è·å–è¿æ¥å¯¹è±¡ï¼Œæ ¹æ®é…ç½®ä½¿ç”¨STSæˆ–ç›´æ¥è®¤è¯"""
        if self.connection:
            return self.connection
        try:
            if self.use_direct_auth:
                print(f"{Fore.BLUE}ä½¿ç”¨ç›´æ¥è®¤è¯æ–¹å¼...")
                self.connection = Connection(
                    access_key_id=config.ACCESS_KEY,
                    access_key_secret=config.SECRET_KEY,
                    host=config.ENDPOINT
                )
            else:
                print(f"{Fore.BLUE}ä½¿ç”¨STSä¸´æ—¶å‡­è¯è®¤è¯æ–¹å¼...")
                # response = requests.get(f"{config.SERVER_URL}/get_sts_token", verify=False)
                # self.sts_token = response.json()
                
                self.connection = Connection(
                    access_key_id=self.sts_token['accessKeyId'],
                    access_key_secret=self.sts_token['secretAccessKey'],
                    security_token=self.sts_token['securityToken'],
                    host=config.ENDPOINT
                )
                
            return self.connection
        except Exception as e:
            print(f"{Fore.RED}è·å–è¿æ¥å¤±è´¥: {str(e)}")
            if self.use_direct_auth:
                print(f"{Fore.RED}è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„ ACCESS_KEY å’Œ SECRET_KEY æ˜¯å¦æ­£ç¡®")
            else:
                print(f"{Fore.RED}STSæœåŠ¡å¯èƒ½ä¸å¯ç”¨ï¼Œè¯·å°è¯•ä½¿ç”¨ç›´æ¥è®¤è¯æ–¹å¼")
            sys.exit(1)
            
    def get_ks3_sts(self):
        """è·å–é‡‘å±±äº‘ks3çš„stsä¿¡æ¯
        Args:
            token: å…·èº«æ•°æ®å¹³å°token
        Returns:
            _type_: æˆåŠŸ/å¤±è´¥
        """
        try:
            # è·å–STSæœåŠ¡ä¸Šä¼ å‡­è¯
            headers = {"Authorization": f"Bearer {self.eai_token}"}
            response = requests.get(f"{config.SERVER_URL}{config.STS_PATH}", headers=headers)
            if "code" in response.json() and response.json()["code"]==200:
                self.sts_token = response.json()["data"]
                return True
        except Exception as e:
            print(f"{Fore.RED}è·å–stså‡­è¯å¤±è´¥: {str(e)}")
        return False

            
                    
    def get_eai_token(self, ak, sk):
        """è·å–é‡‘å±±äº‘ks3çš„stsä¿¡æ¯
        Args:
            ak: å…·èº«æ•°æ®å¹³å°accesskey
            sk: å…·èº«æ•°æ®å¹³å°secretkey
        Returns:
            _type_: å…·èº«æ•°æ®å¹³å°token
        """
        try:
            # è·å–å…·èº«çœŸæœºå¹³å°token
            response = requests.post(f"{config.SERVER_URL}{config.TOKEN_PATH}", json={"ak":ak, "sk":sk})
            if response.status_code == 200:
                if "code" in response.json() and response.json()["code"]==200:
                     self.eai_token = response.json()["data"]['token']
                return self.eai_token
            return None
        except Exception as e:
            print(f"{Fore.RED}è·å–tokenå¤±è´¥: {str(e)}")
            
            
    def get_eai_task(self, task_id):
        """è·å–å…·èº«æ•°æ®å¹³å°ä»»åŠ¡è¯¦æƒ…
        Args:
            task_id: å…·èº«å¹³å°ä»»åŠ¡ID
            token: å…·èº«æ•°æ®å¹³å°token
        """
        try:
            if task_id == -99:
                self.eai_task_id = -99
                return True
            # è·å–STSæœåŠ¡ä¸Šä¼ å‡­è¯
            headers = {"Authorization": self.eai_token}
            response = requests.get(f"{config.SERVER_URL}{config.TASK_PATH}/{task_id}", headers=headers)
            if response.status_code == 200:
                if "code" in response.json() and response.json()["code"]==200:
                    self.eai_task_id = response.json()["data"]["id"]
                    return True
            return False
        except Exception as e:
            print(f"{Fore.RED}è·å–å…·èº«ä»»åŠ¡å¤±è´¥: {str(e)}")
            
        
    def beigin_upload_eai_task(self, data):
        """å¼€å§‹ä¸Šä¼ æ•°æ®é›†ä»»åŠ¡
        Args:
            data: æ•°æ®å®šä¹‰
        Returns:
            _type_: æˆåŠŸ/å¤±è´¥
        """
        try:
            headers = {"Authorization": self.eai_token}
            # è·å–å…·èº«çœŸæœºå¹³å°token
            response = requests.post(f"{config.SERVER_URL}{config.START_UPLOAD_PATH}", headers=headers, json=data)
            if response.status_code == 200:
                if "code" in response.json() and response.json()["code"]==200:
                    self.eai_upload_task_id = response.json()["data"]["uploadTaskId"]
                    return True
            print(f"{Fore.YELLOW}è­¦å‘Šï¼šå¼€å§‹ä¸Šä¼ é€šçŸ¥å¼‚å¸¸,æ•°æ®å¯æ­£å¸¸ä¸Šä¼ ,ä½†åç»­å¹³å°æ— è®°å½•,è¯·è”ç³»ç®¡ç†å‘˜æ’æŸ¥ã€‚å…·ä½“ä¿¡æ¯:{response.json()}")
            return False
        except Exception as e:
            print(f"{Fore.YELLOW}å¼€å§‹ä¸Šä¼ é€šçŸ¥å¼‚å¸¸: {str(e)}")
            
    
    def update_upload_eai_task_progress(self, data):
        """æ›´æ–°æ•°æ®é›†ä¸Šä¼ ä»»åŠ¡è¿›åº¦
        Args:
            data: æ•°æ®å®šä¹‰
        Returns:
            _type_: æˆåŠŸ/å¤±è´¥
        """
        try:
            headers = {"Authorization": self.eai_token}
            # è·å–å…·èº«çœŸæœºå¹³å°token
            response = requests.post(f"{config.SERVER_URL}{config.UPDATE_UPLOAD_PATH}", headers=headers, json=data)
            if response.status_code == 200:
                if "code" in response.json() and response.json()["code"]==200:
                    # self.eai_upload_task_id = response.json()["data"]["uploadTaskId"]
                    return True
            print(f"{Fore.YELLOW}è­¦å‘Šï¼šæ›´æ–°ä¸Šä¼ æ•°æ®é›†è¿›åº¦é€šçŸ¥å¼‚å¸¸,æ•°æ®å¯æ­£å¸¸ä¸Šä¼ ,ä½†å¹³å°è¿›åº¦å¼‚å¸¸,è¯·è”ç³»ç®¡ç†å‘˜æ’æŸ¥ã€‚å…·ä½“ä¿¡æ¯:{response.json()}")
            return False
        except Exception as e:
            print(f"{Fore.YELLOW}è­¦å‘Šï¼šæ›´æ–°ä¸Šä¼ æ•°æ®é›†è¿›åº¦é€šçŸ¥å¼‚å¸¸: {str(e)}")
            
            
    def complete_upload_eai_task(self, status):
        """å®Œæˆæ•°æ®é›†ä¸Šä¼ 
        Args:
            status: SUCCESS/FAILED
        Returns:
            _type_: æˆåŠŸ/å¤±è´¥
        """
        try:
            headers = {"Authorization": self.eai_token}
            # è·å–å…·èº«çœŸæœºå¹³å°token
            response = requests.post(f"{config.SERVER_URL}{config.COMPLETE_UPLOAD_PATH}", headers=headers, json={"upload_task_id":self.eai_upload_task_id, "status": status})
            if response.status_code == 200:
                if "code" in response.json() and response.json()["code"]==200:
                    # self.eai_upload_task_id = response.json()["data"]["uploadTaskId"]
                    return True
            print(f"{Fore.YELLOW}è­¦å‘Šï¼šå®Œæˆæ•°æ®é›†ä¸Šä¼ é€šçŸ¥å¼‚å¸¸,æ•°æ®å¯æ­£å¸¸ä¸Šä¼ ,ä½†å¹³å°çŠ¶æ€å¼‚å¸¸,è¯·è”ç³»ç®¡ç†å‘˜æ’æŸ¥ã€‚å…·ä½“ä¿¡æ¯:{response.json()}")
            return False
        except Exception as e:
            print(f"{Fore.YELLOW}å®Œæˆæ•°æ®é›†ä¸Šä¼ é€šçŸ¥å¼‚å¸¸: {str(e)}") 
            
    
    def upload_file(self, file_path, target_directory, base_dir=None, skip_exist=False, show_progress=False, verify_method="size"):
        """ä¸Šä¼ æ–‡ä»¶
        Args:
            file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            target_directory: è¿œç¨‹æ•°æ®é›†ç›®å½•
            base_dir: åŸºç¡€ç›®å½•è·¯å¾„ï¼ˆç”¨äºè®¡ç®—ç›¸å¯¹è·¯å¾„ï¼‰
            skip_exist: æ˜¯å¦è·³è¿‡ç›®å½•å­˜åœ¨æ£€æŸ¥
            show_progress: æ˜¯å¦å±•ç¤ºè¿›åº¦(æ‰¹é‡ä¸Šä¼ æ—¶é»˜è®¤ä¸ºfalse)
            verify_method: æ–‡ä»¶å†…å®¹éªŒè¯æ–¹æ³• ("size", "md5", "sha256", "strict")
            
        Returns:
            dict: åŒ…å«ä¸Šä¼ ç»“æœçš„å­—å…¸
                - success: bool, æ˜¯å¦æˆåŠŸ
                - skipped: bool, æ˜¯å¦è·³è¿‡
                - message: str, ç»“æœæ¶ˆæ¯
                - file_path: str, æ–‡ä»¶è·¯å¾„
        """
        if not target_directory:
            error_msg = "å¿…é¡»æŒ‡å®šæ•°æ®é›†åç§°"
            print(f"{Fore.RED}é”™è¯¯ï¼š{error_msg}")
            return {"success": False, "skipped": False, "message": error_msg, "file_path": file_path}
            
        if not os.path.exists(file_path):
            error_msg = f"æ–‡ä»¶ä¸å­˜åœ¨ - {file_path}"
            print(f"{Fore.RED}é”™è¯¯ï¼š{error_msg}")
            return {"success": False, "skipped": False, "message": error_msg, "file_path": file_path}
            
        if not os.path.isfile(file_path):
            error_msg = f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶ - {file_path}"
            print(f"{Fore.RED}é”™è¯¯ï¼š{error_msg}")
            return {"success": False, "skipped": False, "message": error_msg, "file_path": file_path}
            
        if not self._is_file_allowed(os.path.basename(file_path)):
            skip_msg = f"è·³è¿‡ä¸ç¬¦åˆè¿‡æ»¤è§„åˆ™çš„æ–‡ä»¶: {file_path}"
            print(f"{Fore.YELLOW}{skip_msg}")
            return {"success": False, "skipped": True, "message": skip_msg, "file_path": file_path}
            
            
        # æœ€å¤§é‡è¯•æ¬¡æ•°
        max_retries = 5
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                connection = self.get_connection()
                
                # è®¡ç®—ç›¸å¯¹è·¯å¾„
                if base_dir:
                    # å°† base_dir å’Œ file_path éƒ½è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
                    abs_base = os.path.abspath(base_dir)   # æœ¬åœ°æ•°æ®æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
                    abs_file = os.path.abspath(file_path)  # æœ¬åœ°æ•°æ®æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
                    
                    # ç¡®ä¿ file_path åœ¨ base_dir ä¸‹
                    if not abs_file.startswith(abs_base):
                        error_msg = f"æ–‡ä»¶è·¯å¾„ {file_path} ä¸åœ¨åŸºç¡€ç›®å½• {base_dir} ä¸‹"
                        raise ValueError(error_msg)
                    
                    # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œå°†Windowsè·¯å¾„åˆ†éš”ç¬¦è½¬æ¢ä¸ºæ­£æ–œæ 
                    rel_path = os.path.relpath(abs_file, abs_base).replace('\\', '/').lstrip('/')
                    # æ„å»ºç›®æ ‡é”®,é¿å…æ“ä½œç³»ç»Ÿè·¯å¾„é—®é¢˜
                    key = f"{config.UPLOAD_TARGET}/{target_directory}/{rel_path}"
                else:
                    # å¦‚æœæ²¡æœ‰æŒ‡å®š base_dirï¼Œåˆ™ç›´æ¥ä½¿ç”¨æ–‡ä»¶å
                    key = f"{config.UPLOAD_TARGET}/{target_directory}/{os.path.basename(file_path)}"

                # æ˜¯å¦è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
                if skip_exist:
                    # è·³è¿‡åˆ™æ£€æŸ¥æ˜¯å¦å­˜åœ¨å½“å‰ä¸Šä¼ æ–‡ä»¶
                    bucket = connection.get_bucket(config.BUCKET_NAME)
                    # æ£€æŸ¥å…·ä½“çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    try:
                        existing = list(bucket.list(prefix=key, delimiter='/', max_keys=1))
                        if existing:
                            # æ–‡ä»¶å­˜åœ¨ï¼Œéœ€è¦éªŒè¯å†…å®¹æ˜¯å¦ä¸€è‡´
                            if self._verify_file_content(file_path, existing[0], verify_method):
                                skip_msg = f"æ–‡ä»¶å·²å­˜åœ¨ä¸”å†…å®¹ä¸€è‡´ï¼Œè·³è¿‡ä¸Šä¼ : {file_path}"
                                print(f"{Fore.YELLOW}{skip_msg}")
                                return {"success": False, "skipped": True, "message": skip_msg, "file_path": file_path}
                            else:
                                print(f"{Fore.BLUE}æ–‡ä»¶å·²å­˜åœ¨ä½†å†…å®¹ä¸ä¸€è‡´ï¼Œå°†è¦†ç›–ä¸Šä¼ : {file_path}")
                    except Exception:
                        # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œç»§ç»­ä¸Šä¼ 
                        pass
                
                file_size = os.path.getsize(file_path)
                
                # å¤§å°æ–‡ä»¶çš„ä¸Šä¼ é€»è¾‘
                if file_size > 5 * 1024 * 1024:  # 5MB
                    self._multipart_upload_ks3_sdk(file_path, key, show_progress)
                    # self._multipart_upload(file_path, key, show_progress)
                else:
                    self._simple_upload(file_path, key, show_progress)
                    
                success_msg = f"æˆåŠŸä¸Šä¼ : {file_path} åˆ° {key}"
                print(f"{Fore.GREEN}{success_msg}")      
                # ä¸Šä¼ æˆåŠŸï¼Œè·³å‡ºå¾ªç¯
                return {"success": True, "skipped": False, "message": success_msg, "file_path": file_path}

            except Exception as e:
                retry_count += 1
                if retry_count < max_retries:
                    print(f"{Fore.YELLOW}ä¸Šä¼ å¤±è´¥ {file_path}: {str(e)}ï¼Œæ­£åœ¨è¿›è¡Œç¬¬ {retry_count} æ¬¡é‡è¯•...")
                else:
                    error_msg = f"ä¸Šä¼ å¤±è´¥ {file_path}: {str(e)}ï¼Œå·²é‡è¯• {retry_count} æ¬¡ï¼Œæ”¾å¼ƒä¸Šä¼ "
                    print(f"{Fore.RED}{error_msg}")
                    return {"success": False, "skipped": False, "message": error_msg, "file_path": file_path}
                
                import time
                # é‡è¯•å‰ç­‰å¾…ä¸€æ®µæ—¶é—´
                time.sleep(2)


    
    def _handle_duplicate_dataset(self, sub_dir):
        """å¤„ç†é‡å¤çš„æ•°æ®é›†åç§°
        
        Returns:
            str or None: è¿”å›æ–°çš„æ•°æ®é›†åç§°ï¼Œå¦‚æœç”¨æˆ·å–æ¶ˆåˆ™è¿”å›None
        """
        while True:
            choice = input(f"{Fore.YELLOW}ç›®æ ‡æ•°æ®é›† '{sub_dir}' å·²å­˜åœ¨ã€‚è¯·é€‰æ‹©æ“ä½œ:\n"
                          f"1. ä½¿ç”¨å¦ä¸€ä¸ªæ•°æ®é›†åç§°\n"
                          f"2. ç»§ç»­ä½¿ç”¨æ­¤æ•°æ®é›†åç§°\n"
                          f"3. å–æ¶ˆä¸Šä¼ \n"
                          f"è¯·é€‰æ‹© [1/2/3]: ")
            
            if choice == '1':
                new_name = input(f"{Fore.BLUE}è¯·è¾“å…¥æ–°çš„ç›®æ ‡æ•°æ®é›†è·¯å¾„: ")
                if not new_name:
                    print(f"{Fore.RED}é”™è¯¯ï¼šç›®æ ‡æ•°æ®é›†è·¯å¾„ä¸èƒ½ä¸ºç©º")
                    continue
                if not has_any_path_separator(sub_dir):
                    print(f"{Fore.RED}é”™è¯¯: å¿…é¡»è‡³å°‘å«æœ‰1ä¸ªè·¯å¾„åˆ†éš”ç¬¦'/',å¦‚:a/b")
                    continue
                # é€’å½’æ£€æŸ¥æ–°åç§°æ˜¯å¦ä¹Ÿå­˜åœ¨
                bucket = self.get_connection().get_bucket(config.BUCKET_NAME)
                prefix = f"{config.UPLOAD_TARGET}/{new_name}"
                existing = list(bucket.list(prefix=prefix, delimiter='/', max_keys=1))
                
                if existing:
                    return self._handle_duplicate_dataset(new_name)
                return new_name
            elif choice == '2':
                return sub_dir
            elif choice == '3':
                return None
            else:
                print(f"{Fore.RED}æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def _simple_upload(self, file_path, key, show_progress=False):
        """ç®€å•ä¸Šä¼ """
        file_size = os.path.getsize(file_path)
        
        if show_progress:
            pbar = tqdm(total=file_size,
                        bar_format = "{l_bar}{bar:40}| {percentage:.0f}% [{elapsed}<{remaining}, {rate_fmt}{postfix}]",
                        colour = "GREEN" , # ä½¿ç”¨æ ‡å‡†ç»¿è‰²è€Œéåå…­è¿›åˆ¶é¢œè‰²ç 
                        dynamic_ncols = True , # è‡ªåŠ¨é€‚åº”ç»ˆç«¯å®½åº¦
                        unit='B', 
                        unit_scale=True, 
                        desc=os.path.basename(file_path))
        
        with open(file_path, 'rb') as f:
            bucket = self.get_connection().get_bucket(config.BUCKET_NAME)
            k = bucket.new_key(key)
            
            
            k.set_contents_from_file(f)
            if show_progress:
                pbar.update(file_size)
        
        if show_progress:
            pbar.close()
    
    def _multipart_upload(self, file_path, key, show_progress=False):
        """åˆ†ç‰‡ä¸Šä¼ """        
        chunk_size = 5 * 1024 * 1024  # 5MBåˆ†ç‰‡
        file_size = os.path.getsize(file_path)
        
        bucket = self.connection.get_bucket(config.BUCKET_NAME)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„ä¸Šä¼ 
        resume_info = self._get_resume_info(file_path)
        if resume_info and resume_info['key'] == key:
            # æ¢å¤æœªå®Œæˆçš„ä¸Šä¼ 
            mp = bucket.get_all_multipart_uploads(prefix=key)[0]
            upload_id = resume_info['upload_id']
            completed_parts = resume_info['completed_parts']
            
            # todo æ¢å¤mpçš„part_crc_infosçŠ¶æ€(mpå¯¹è±¡ä¸Šä¼ æ—¶ä¼šåœ¨æœ¬åœ°å†…å­˜ç»´æŠ¤part_infoï¼Œç”¨äºå®Œæˆä¸Šä¼ æ—¶æ ¡éªŒæ•´ä¸ªæ–‡ä»¶çš„crcã€‚part_infoä¸å®Œæ•´ä¼šå¯¼è‡´æœ¬åœ°è®¡ç®—crcå‡ºé”™ã€‚)
            for part in completed_parts:
                # from ks3.multipart import PartInfo
                mp.part_crc_infos[part['PartNumber']] = PartInfo(part['PartSize'], part['Crc64ecma'])
            
            start_part = len(completed_parts) + 1
            # if show_progress:
            print(f"{Fore.GREEN}å‘ç°{key}çš„æ–­ç‚¹ç»­ä¼ ä¿¡æ¯ï¼Œä»ç¬¬ {start_part} éƒ¨åˆ†ç»§ç»­ä¸Šä¼ ")
        else:
            # åˆå§‹åŒ–æ–°çš„åˆ†ç‰‡ä¸Šä¼ 
            mp = bucket.initiate_multipart_upload(key)
            upload_id = mp.id
            completed_parts = []
            start_part = 1
            
        # è®¡ç®—åˆ†ç‰‡æ•°é‡
        chunk_count = int(math.ceil(file_size * 1.0 / chunk_size))
        
        if show_progress:
            pbar = tqdm(total=file_size, 
                        bar_format = "{l_bar}{bar:40}| {percentage:.0f}% [{elapsed}<{remaining}, {rate_fmt}{postfix}]",
                        colour = "GREEN" , # ä½¿ç”¨æ ‡å‡†ç»¿è‰²è€Œéåå…­è¿›åˆ¶é¢œè‰²ç  
                        dynamic_ncols = True , # è‡ªåŠ¨é€‚åº”ç»ˆç«¯å®½åº¦
                        unit='B', 
                        unit_scale=True, 
                        desc=os.path.basename(file_path))
            completed_bytes = (start_part - 1) * chunk_size
            pbar.update(completed_bytes)
        
        try:
            for i in range(start_part - 1, chunk_count):
                offset = chunk_size * i
                bytes_to_read = min(chunk_size, file_size - offset)
                
                with FileChunkIO(file_path, 'r', offset=offset, bytes=bytes_to_read) as fp:
                    # ä¸Šä¼ åˆ†ç‰‡                   
                    part_num = i + 1
                    ret = mp.upload_part_from_file(fp, part_num=part_num)
                    
                    if show_progress:
                        pbar.update(bytes_to_read)
                    
                    completed_parts.append({
                        'PartNumber': part_num,
                        # todo é¢å¤–ä¿å­˜å—å¤§å°ã€å—crc64ä¿¡æ¯
                        'PartSize': bytes_to_read,
                        'ETag': ret.response_metadata.headers['ETag'],  # todo æ”¹ä¸ºäº†ä¿å­˜ETagä¿¡æ¯
                        'Crc64ecma': ret.response_metadata.headers['x-kss-checksum-crc64ecma']
                    })
                    
                    # ä¿å­˜æ–­ç‚¹ç»­ä¼ ä¿¡æ¯
                    self._save_resume_info(file_path, {
                        'key': key,
                        'upload_id': upload_id,
                        'completed_parts': completed_parts
                    })
            
            mp.complete_upload()
            self._delete_resume_info(file_path)
         
        except Exception as e:
            print(f"{Fore.RED}ä¸Šä¼ å¤±è´¥ {file_path}: {str(e)}")
            raise
        finally:
            if show_progress:
                pbar.close()
    
    def _multipart_upload_ks3_sdk(self, file_path, key, show_progress=False):
        """
        ä½¿ç”¨ key.upload_file æ–¹æ³•è¿›è¡Œå¤§æ–‡ä»¶åˆ†ç‰‡ä¸Šä¼ ï¼Œé€šè¿‡å›è°ƒå‡½æ•°å±•ç¤ºè¿›åº¦
        
        Args:
            file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            key: ç›®æ ‡å­˜å‚¨é”®
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        """
        file_size = os.path.getsize(file_path)
        
        # å‡†å¤‡è¿›åº¦æ¡
        if show_progress:
            pbar = tqdm(total=file_size,
                        bar_format="{l_bar}{bar:40}| {percentage:.0f}% [{elapsed}<{remaining}, {rate_fmt}{postfix}]",
                        colour="GREEN",
                        dynamic_ncols=True,
                        unit='B',
                        unit_scale=True,
                        desc=os.path.basename(file_path))

            try:
                bucket = self.connection.get_bucket(config.BUCKET_NAME)
                k = bucket.new_key(key)
                
                k.upload_file(
                    filename=file_path,
                    part_size=5 * 1024 * 1024,  # 5MB åˆ†ç‰‡
                    threads_num=5,              # 5çº¿ç¨‹å¹¶å‘
                    resumable=True,             # å¼€å¯æ–­ç‚¹ç»­ä¼ 
                    resumable_filename=os.path.join(self.resume_dir, f"{self._get_file_md5(file_path)}.ks3resume"),
                    headers={'x-kss-storage-class': 'STANDARD'} # æ ‡å‡†å­˜å‚¨
                )
                
            except Exception as e:
                print(f"{Fore.RED}ä¸Šä¼ å¤±è´¥ {file_path}: {str(e)}")
                raise e
            finally:
                pbar.close()
                
        else:
            # ä¸æ˜¾ç¤ºè¿›åº¦æ¡çš„ä¸Šä¼ 
            try:
                bucket = self.connection.get_bucket(config.BUCKET_NAME)
                k = bucket.new_key(key)
                
                k.upload_file(
                    filename=file_path,
                    part_size=5 * 1024 * 1024,
                    threads_num=5,
                    resumable=True,
                    resumable_filename=os.path.join(self.resume_dir, f"{self._get_file_md5(file_path)}.ks3resume"),
                    headers={'x-kss-storage-class': 'STANDARD'}
                )
            except Exception as e:
                raise e
    
    def batch_upload(self, directory=None, target_directory=None, file_list=None, skip_exist=False, show_progress=False, verify_method="size") -> UploadResult:
        """æ‰¹é‡ä¸Šä¼ ç›®å½•ä¸‹çš„æ–‡ä»¶æˆ–æŒ‡å®šæ–‡ä»¶åˆ—è¡¨
        
        Args:
            directory: æœ¬åœ°æ•°æ®é›†ç›®å½•è·¯å¾„ï¼ˆä¸file_listäºŒé€‰ä¸€ï¼‰
            target_directory: è¿œç¨‹æ•°æ®é›†ç›®å½•è·¯å¾„
            file_list: æŒ‡å®šè¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆä¸directoryäºŒé€‰ä¸€ï¼‰
            skip_exist: æ˜¯å¦è·³è¿‡åŒåæ–‡ä»¶
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            verify_method: æ–‡ä»¶å†…å®¹éªŒè¯æ–¹æ³• ("size", "md5", "sha256", "strict")
            
        Returns:
            UploadResult: åŒ…å«codeã€msgå’Œdataçš„è§„èŒƒåŒ–ç»“æœ
                - code: è¿”å›ç  (200æˆåŠŸ, 400å‚æ•°é”™è¯¯, 404èµ„æºæœªæ‰¾åˆ°, 409å†²çª, 500ç³»ç»Ÿé”™è¯¯, 499å–æ¶ˆ)
                - msg: è¿”å›æ¶ˆæ¯
                - data: è¿”å›æ•°æ®ï¼ŒåŒ…å«ä¸Šä¼ ç»Ÿè®¡ä¿¡æ¯
        """
        # å‚æ•°æ ¡éªŒ
        if not target_directory:
            error_msg = "å¿…é¡»æŒ‡å®šæ•°æ®é›†è·¯å¾„"
            print(f"{Fore.RED}é”™è¯¯ï¼š{error_msg}")
            return UploadResult.param_error(error_msg)
                    
        if not has_any_path_separator(target_directory):
            error_msg = "å¿…é¡»è‡³å°‘å«æœ‰1ä¸ªè·¯å¾„åˆ†éš”ç¬¦'/',å¦‚:a/b"
            print(f"{Fore.RED}é”™è¯¯: {error_msg}")
            return UploadResult.param_error(error_msg)

            
        # æ£€æŸ¥æ˜¯å¦åŒæ—¶æä¾›äº†directoryå’Œfile_list
        if directory is not None and file_list is not None:
            error_msg = "ä¸èƒ½åŒæ—¶æŒ‡å®šdirectoryå’Œfile_listå‚æ•°ï¼Œè¯·é€‰æ‹©å…¶ä¸­ä¸€ç§æ–¹å¼"
            print(f"{Fore.RED}é”™è¯¯ï¼š{error_msg}")
            return UploadResult.param_error(error_msg)
        
        # æ£€æŸ¥æ˜¯å¦è‡³å°‘æä¾›äº†ä¸€ä¸ªå‚æ•°
        if directory is None and file_list is None:
            error_msg = "å¿…é¡»æŒ‡å®šdirectoryæˆ–file_listå‚æ•°ä¹‹ä¸€"
            print(f"{Fore.RED}é”™è¯¯ï¼š{error_msg}")
            return UploadResult.param_error(error_msg)
        
        # å¤„ç†æ–‡ä»¶åˆ—è¡¨æ¨¡å¼
        if file_list is not None:
            return self._batch_upload_files(file_list, target_directory, skip_exist, show_progress, verify_method)
        
        # å¤„ç†ç›®å½•æ¨¡å¼
        return self._batch_upload_directory(directory, target_directory, skip_exist, show_progress, verify_method)
 
    def _batch_upload_files(self, file_list, target_directory, skip_exist=False, show_progress=False, verify_method="size") -> UploadResult:
        """æ‰¹é‡ä¸Šä¼ æŒ‡å®šæ–‡ä»¶åˆ—è¡¨
        
        Args:
            file_list: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            target_directory: è¿œç¨‹æ•°æ®é›†ç›®å½•è·¯å¾„
            skip_exist: æ˜¯å¦è·³è¿‡åŒåæ–‡ä»¶
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            verify_method: æ–‡ä»¶å†…å®¹éªŒè¯æ–¹æ³•
            
        Returns:
            UploadResult: ä¸Šä¼ ç»“æœ
        """
        # æ–‡ä»¶åˆ—è¡¨æ ¡éªŒ
        if not isinstance(file_list, (list, tuple)):
            error_msg = "file_listå‚æ•°å¿…é¡»æ˜¯åˆ—è¡¨æˆ–å…ƒç»„ç±»å‹"
            print(f"{Fore.RED}é”™è¯¯ï¼š{error_msg}")
            return UploadResult.param_error(error_msg)
        
        if not file_list:
            error_msg = "file_listä¸èƒ½ä¸ºç©º"
            print(f"{Fore.RED}é”™è¯¯ï¼š{error_msg}")
            return UploadResult.param_error(error_msg)
        
        # æ ¡éªŒæ¯ä¸ªæ–‡ä»¶è·¯å¾„
        valid_files = []
        invalid_files = []
        total_size = 0
        
        for file_path in file_list:
            # æ£€æŸ¥æ–‡ä»¶è·¯å¾„ç±»å‹
            if not isinstance(file_path, str):
                invalid_files.append((file_path, "æ–‡ä»¶è·¯å¾„å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹"))
                continue
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                invalid_files.append((file_path, "æ–‡ä»¶ä¸å­˜åœ¨"))
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
            if not os.path.isfile(file_path):
                invalid_files.append((file_path, "è·¯å¾„ä¸æ˜¯æ–‡ä»¶"))
                continue
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»
            if not os.access(file_path, os.R_OK):
                invalid_files.append((file_path, "æ–‡ä»¶ä¸å¯è¯»"))
                continue
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            try:
                file_size = os.path.getsize(file_path)
                if file_size == 0:
                    invalid_files.append((file_path, "æ–‡ä»¶å¤§å°ä¸º0"))
                    continue
                total_size += file_size
            except OSError as e:
                invalid_files.append((file_path, f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {str(e)}"))
                continue
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç¬¦åˆè¿‡æ»¤è§„åˆ™
            if not self._is_file_allowed(os.path.basename(file_path)):
                invalid_files.append((file_path, "æ–‡ä»¶ä¸ç¬¦åˆè¿‡æ»¤è§„åˆ™"))
                continue
            
            valid_files.append((file_path, file_size))
        
        # æŠ¥å‘Šæ— æ•ˆæ–‡ä»¶
        if invalid_files:
            print(f"{Fore.YELLOW}å‘ç° {len(invalid_files)} ä¸ªæ— æ•ˆæ–‡ä»¶:")
            for file_path, reason in invalid_files:
                print(f"{Fore.YELLOW}  - {file_path}: {reason}")
        
        if not valid_files:
            error_msg = "æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶å¯ä»¥ä¸Šä¼ "
            print(f"{Fore.RED}é”™è¯¯ï¼š{error_msg}")
            return UploadResult.param_error(error_msg)
        
        # æ£€æŸ¥ç›®æ ‡ç›®å½•å†²çª
        # connection = self.get_connection()
        # bucket = connection.get_bucket(config.BUCKET_NAME)
        # prefix = f"{config.UPLOAD_TARGET}/{target_directory}"
        # existing = list(bucket.list(prefix=prefix, delimiter='/', max_keys=1))
        
        # if existing:
        #     new_sub_dir = self._handle_duplicate_dataset(target_directory)
        #     if not new_sub_dir:
        #         return UploadResult.cancelled("ç”¨æˆ·å–æ¶ˆä¸Šä¼ ")
        #     target_directory = new_sub_dir
        
        print(f"{Fore.BLUE}å‡†å¤‡ä¸Šä¼  {len(valid_files)} ä¸ªæ–‡ä»¶ (æ€»å¤§å°: {total_size/1024/1024:.2f}MB)...")
        
        # æ‰§è¡Œä¸Šä¼ 
        return self._execute_upload(valid_files, target_directory, show_progress, source_type="file_list", skip_exist=skip_exist, verify_method=verify_method)
    
    def _batch_upload_directory(self, directory, target_directory, skip_exist=False, show_progress=False, verify_method="size") -> UploadResult:
        """æ‰¹é‡ä¸Šä¼ ç›®å½•ä¸‹çš„æ–‡ä»¶
        
        Args:
            directory: æœ¬åœ°æ•°æ®é›†ç›®å½•è·¯å¾„
            target_directory: è¿œç¨‹æ•°æ®é›†ç›®å½•è·¯å¾„
            skip_exist: æ˜¯å¦è·³è¿‡åŒåæ–‡ä»¶
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            verify_method: æ–‡ä»¶å†…å®¹éªŒè¯æ–¹æ³•
            
        Returns:
            UploadResult: ä¸Šä¼ ç»“æœ
        """
        if not os.path.exists(directory):
            error_msg = f"è·¯å¾„ç›®å½•ä¸å­˜åœ¨ - {directory}"
            print(f"{Fore.RED}é”™è¯¯ï¼š{error_msg}")
            return UploadResult.not_found(error_msg)
            
        if not os.path.isdir(directory):
            error_msg = f"è·¯å¾„ä¸æ˜¯ç›®å½• - {directory}"
            print(f"{Fore.RED}é”™è¯¯ï¼š{error_msg}")
            return UploadResult.param_error(error_msg)
        
        # æ£€æŸ¥ç›®æ ‡ç›®å½•å†²çª
        # connection = self.get_connection()
        # bucket = connection.get_bucket(config.BUCKET_NAME)
        # prefix = f"{config.UPLOAD_TARGET}/{target_directory}"
        # existing = list(bucket.list(prefix=prefix, delimiter='/', max_keys=1))
        
        # if existing:
        #     new_sub_dir = self._handle_duplicate_dataset(target_directory)
        #     if not new_sub_dir:
        #         return UploadResult.cancelled("ç”¨æˆ·å–æ¶ˆä¸Šä¼ ")
        #     target_directory = new_sub_dir
            
        # æ”¶é›†ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶åŠå…¶å¤§å°
        files_info = []
        total_size = 0
        for root, _, filenames in os.walk(directory):
            for filename in filenames:
                if self._is_file_allowed(filename):
                    file_path = os.path.join(root, filename)
                    size = os.path.getsize(file_path)
                    files_info.append((file_path, size))
                    total_size += size
                else:
                    print(f"{Fore.YELLOW}è·³è¿‡ä¸ç¬¦åˆè¿‡æ»¤è§„åˆ™çš„æ–‡ä»¶: {filename}")
        
        if not files_info:
            warning_msg = f"åœ¨ç›®å½• {directory} ä¸­æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆè¿‡æ»¤è§„åˆ™çš„æ–‡ä»¶"
            print(f"{Fore.YELLOW}è­¦å‘Šï¼š{warning_msg}")
            return UploadResult.param_error(warning_msg)
        
        print(f"{Fore.BLUE}æ‰¾åˆ° {len(files_info)} ä¸ªæ–‡ä»¶ (æ€»å¤§å°: {total_size/1024/1024:.2f}MB) å‡†å¤‡ä¸Šä¼ ...")
        
        # æ‰§è¡Œä¸Šä¼ 
        return self._execute_upload(files_info, target_directory, show_progress, source_type="directory", base_dir=directory, skip_exist=skip_exist, verify_method=verify_method)
    
    def _execute_upload(self, files_info, target_directory, show_progress=False, source_type="directory", base_dir=None, skip_exist=False, verify_method="size") -> UploadResult:
        """æ‰§è¡Œæ‰¹é‡ä¸Šä¼ çš„æ ¸å¿ƒé€»è¾‘
        
        Args:
            files_info: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (file_path, file_size)
            target_directory: è¿œç¨‹æ•°æ®é›†ç›®å½•è·¯å¾„
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            source_type: æ¥æºç±»å‹ ("directory" æˆ– "file_list")
            base_dir: åŸºç¡€ç›®å½•è·¯å¾„ï¼ˆä»…ç”¨äºç›®å½•æ¨¡å¼ï¼‰
            skip_exist: æ˜¯å¦è·³è¿‡å·²ä¸Šä¼ çš„æ–‡ä»¶
            verify_method: æ–‡ä»¶å†…å®¹éªŒè¯æ–¹æ³•
        Returns:
            UploadResult: ä¸Šä¼ ç»“æœ
        """
        # æŒ‰æ–‡ä»¶å¤§å°æ’åºï¼Œä¾¿äºå‡åŒ€åˆ†é…
        files_info.sort(key=lambda x: x[1], reverse=True)
        
        # å°†æ–‡ä»¶åˆ†é…ç»™ä¸åŒçº¿ç¨‹ï¼Œå°½é‡ä¿è¯æ¯ä¸ªçº¿ç¨‹å¤„ç†çš„æ•°æ®é‡æ¥è¿‘
        max_workers = min(self.max_worker, len(files_info)) 
        thread_files = [[] for _ in range(max_workers)]   
        thread_sizes = [0] * max_workers
        
        # ä½¿ç”¨è´ªå¿ƒç®—æ³•åˆ†é…æ–‡ä»¶
        for file_path, size in files_info:
            # æ‰¾åˆ°å½“å‰æ€»å¤§å°æœ€å°çš„çº¿ç¨‹
            min_size_thread = min(range(max_workers), key=lambda i: thread_sizes[i])
            thread_files[min_size_thread].append(file_path)
            thread_sizes[min_size_thread] += size
        
        # å®šä¹‰çº¿ç¨‹ä¸Šä¼ ä»»åŠ¡
        def upload_task_thread(thread_id, files, total_size):
            try:
                # ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„ä¸Šä¼ å™¨å®ä¾‹
                thread_uploader = BaaiRobotDataUploader(use_direct_auth=self.use_direct_auth)
                thread_uploader.set_sts_token(self.sts_token)
                # ä½¿ç”¨çº¿ç¨‹æœ¬åœ°å˜é‡è·Ÿè¸ªå½“å‰çº¿ç¨‹çš„æˆåŠŸã€å¤±è´¥å’Œè·³è¿‡æ–‡ä»¶
                local_success_files = []
                local_failed_files = []
                local_skipped_files = []
                
                if show_progress:
                    pbar = tqdm(total=total_size, 
                            unit='B', 
                            colour = "GREEN" , # ä½¿ç”¨æ ‡å‡†ç»¿è‰²è€Œéåå…­è¿›åˆ¶é¢œè‰²ç 
                            dynamic_ncols = True , # è‡ªåŠ¨é€‚åº”ç»ˆç«¯å®½åº¦
                            unit_scale=True, 
                            desc=f"ğŸŸ¢ çº¿ç¨‹-{thread_id}", leave=True,
                            position=thread_id)
                                    
                for file_path in files:
                    file_size = os.path.getsize(file_path)
                    try:
                        # æ ¹æ®æ¥æºç±»å‹å†³å®šæ˜¯å¦ä¼ å…¥åŸºç¡€ç›®å½•å‚æ•°
                        if source_type == "directory" and base_dir:
                            result = thread_uploader.upload_file(
                                file_path, 
                                target_directory,
                                base_dir=base_dir,  # æ·»åŠ åŸºç¡€ç›®å½•å‚æ•°
                                skip_exist=skip_exist, 
                                show_progress=False,
                                verify_method=verify_method
                            )
                        else:
                            result = thread_uploader.upload_file(
                                file_path, 
                                target_directory,
                                skip_exist=skip_exist, 
                                show_progress=False,
                                verify_method=verify_method
                            )
                        
                        # å¤„ç†ä¸Šä¼ ç»“æœ
                        if result:
                            if result.get("success", False):
                                local_success_files.append(file_path)
                            elif result.get("skipped", False):
                                local_skipped_files.append(file_path)
                            else:
                                local_failed_files.append(file_path)
                        else:
                            local_failed_files.append(file_path)
                            
                    except Exception as e:
                        print(f"{Fore.RED}ä¸Šä¼ å¤±è´¥ {file_path}: {str(e)}")
                        local_failed_files.append(file_path)                            
                    finally:
                        if show_progress:
                            # æ›´æ–°è¿›åº¦æ¡
                            pbar.update(file_size)

                if show_progress:
                    pbar.close()
                return local_success_files, local_failed_files, local_skipped_files
            except Exception as e:
                print(f"{thread_id}-error:{e}")
                return [], [], []
                
        # ç”±äºä½¿ç”¨äº†tqdmçš„positionå‚æ•°æ¥æ˜¾ç¤ºå¤šä¸ªè¿›åº¦æ¡
        # éœ€è¦é¢„å…ˆæ‰“å°è¶³å¤Ÿçš„ç©ºè¡Œä¸ºè¿›åº¦æ¡é¢„ç•™æ˜¾ç¤ºç©ºé—´
        if show_progress:
            print("\n" * (max_workers + 1))
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œä¸Šä¼ 
        success_count = 0
        failure_count = 0
        skipped_count = 0
        success_files, failure_files, skipped_files = [], [], []
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            for i in range(max_workers):
                if thread_files[i]:  # åªä¸ºæœ‰æ–‡ä»¶çš„çº¿ç¨‹åˆ›å»ºä»»åŠ¡
                    future = executor.submit(
                        upload_task_thread,
                        i,  # thread_id
                        thread_files[i],  # è¯¥çº¿ç¨‹è´Ÿè´£çš„æ–‡ä»¶åˆ—è¡¨
                        thread_sizes[i]   # è¯¥çº¿ç¨‹è´Ÿè´£çš„æ–‡ä»¶æ€»å¤§å°
                    )
                    futures.append(future)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in futures:
                local_success, local_failed, local_skipped = future.result()
                success_count += len(local_success)
                success_files.extend(local_success)
                failure_count += len(local_failed)
                failure_files.extend(local_failed)
                skipped_count += len(local_skipped)
                skipped_files.extend(local_skipped)

        
        # ç”±äºtqdmè¿›åº¦æ¡ä¼šå ç”¨ç»ˆç«¯ç©ºé—´
        # ä»»åŠ¡å®Œæˆåéœ€è¦æ‰“å°ç›¸åŒæ•°é‡çš„æ¢è¡Œæ¥"æ¸…ç†"è¿™äº›è¿›åº¦æ¡
        # å¦åˆ™åç»­è¾“å‡ºä¼šç´§è´´åœ¨è¿›åº¦æ¡ä¸Š
        if show_progress:
            print("\n" * (max_workers + 1))
        
        # è®¡ç®—æ€»å¤§å°
        total_size = sum(size for _, size in files_info)
        
        # æ„å»ºè¿”å›æ•°æ®
        result_data = {
            "upload_task_id": self.eai_upload_task_id,
            "total_files": len(files_info),
            "success_count": success_count,
            "failure_count": failure_count,
            "skipped_count": skipped_count,
            "success_files": success_files,
            "failure_files": failure_files,
            "skipped_files": skipped_files,
            "total_size_mb": total_size / 1024 / 1024,
            "target_directory": target_directory,
            "source_type": source_type
        }
        
        # æ ¹æ®æ¥æºç±»å‹æ·»åŠ ä¸åŒçš„æºä¿¡æ¯
        if source_type == "directory":
            result_data["source_directory"] = base_dir
        else:
            result_data["source_file_list"] = [file_path for file_path, _ in files_info]
        
        # æ‰“å°æœ€ç»ˆç»“æœ
        print(f"\n{Fore.GREEN}æ‰¹é‡ä¸Šä¼ å®Œæˆ,ä¸Šä¼ ID:{self.eai_upload_task_id},å¯åœ¨æ•°æ®ä¸Šä¼ ä¼ è¾“åˆ—è¡¨æŸ¥çœ‹")
        print(f"{Fore.GREEN}æˆåŠŸ: {success_count} ä¸ªæ–‡ä»¶")
        if skipped_count > 0:
            print(f"{Fore.YELLOW}è·³è¿‡: {skipped_count} ä¸ªæ–‡ä»¶")
        if failure_count > 0:
            print(f"{Fore.RED}å¤±è´¥: {failure_count} ä¸ªæ–‡ä»¶ï¼Œæ–‡ä»¶åˆ—è¡¨:{failure_files}")
        
        # æ ¹æ®å¤±è´¥æƒ…å†µè¿”å›ä¸åŒçš„ç»“æœ
        if failure_count == 0:
            if skipped_count > 0:
                success_msg = f"æ‰¹é‡ä¸Šä¼ æˆåŠŸï¼Œå…±ä¸Šä¼  {success_count} ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡ {skipped_count} ä¸ªæ–‡ä»¶"
            else:
                success_msg = f"æ‰¹é‡ä¸Šä¼ æˆåŠŸï¼Œå…±ä¸Šä¼  {success_count} ä¸ªæ–‡ä»¶"
            return UploadResult.success(success_msg, result_data)
        elif success_count > 0:
            partial_msg = f"æ‰¹é‡ä¸Šä¼ éƒ¨åˆ†æˆåŠŸï¼ŒæˆåŠŸ {success_count} ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡ {skipped_count} ä¸ªæ–‡ä»¶ï¼Œå¤±è´¥ {failure_count} ä¸ªæ–‡ä»¶"
            return UploadResult.fail(ResultCode.SYSTEM_ERROR, partial_msg, result_data)
        else:
            fail_msg = f"æ‰¹é‡ä¸Šä¼ å¤±è´¥ï¼Œæ‰€æœ‰ {failure_count} ä¸ªæ–‡ä»¶éƒ½ä¸Šä¼ å¤±è´¥"
            return UploadResult.fail(ResultCode.SYSTEM_ERROR, fail_msg, result_data)
 

    
# ä½¿ç”¨ç¤ºä¾‹å’Œæ–‡æ¡£
def all_example_usage():
    """ä½¿ç”¨ç¤ºä¾‹ï¼šå±•ç¤ºå¦‚ä½•è°ƒç”¨ä¼˜åŒ–åçš„batch_uploadå‡½æ•°"""
    
    # åˆ›å»ºä¸Šä¼ å™¨å®ä¾‹
    uploader = BaaiRobotDataUploader(use_direct_auth=False)
    
    # è®¾ç½®è®¤è¯ä¿¡æ¯
    token = "Bearer eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJhZG1pbiIsImxvZ2luX3VzZXJfa2V5IjoiMzlkNDRmMzEtZmUyNS00Y2ZkLTgyY2EtMGUwZDU0MDc3NzE4In0.uHKF2iyoD1ZEDc7HYjFgzpO24TrKxYGhnYtm7r8hnOGDBgE-Z3evmHgqNlQTRGy4K9cDiv59HpDFTSgbZRDY7A"
    uploader.set_eai_token(eai_token=token)
    uploader.get_ks3_sts()
    uploader.set_max_worker(4)
    # uploader.set_file_filters(["*.txt", "*.csv", "*.json"])
    
    print("=" * 60)
    print("ğŸ“ ç¤ºä¾‹1: ä¸Šä¼ ç›®å½•")
    print("=" * 60)
    
    # ç¤ºä¾‹1: ä¸Šä¼ ç›®å½•
    result1 = uploader.batch_upload(
        directory="/Users/catkinliu/Desktop/nas/å è¡£æœ_1813490901",
        target_directory="suibian/nas",
        skip_exist=False,
        show_progress=False
    )
    
    print("\n" + "=" * 60)
    print("ğŸ“„ ç¤ºä¾‹2: ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨")
    print("=" * 60)
    
    # ç¤ºä¾‹2: ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨
    file_list = [
        "/path/to/file1.txt",
        "/path/to/file2.csv", 
        "/path/to/file3.json"
    ]
    
    result2 = uploader.batch_upload(
        file_list=file_list,
        target_directory="suibian/files",
        skip_exist=False,
        show_progress=False
    )
    
    print("\n" + "=" * 60)
    print("ğŸ“„ ç¤ºä¾‹3: æ–‡ä»¶åˆ—è¡¨æ ¡éªŒæ¼”ç¤º")
    print("=" * 60)
    
    # ç¤ºä¾‹3: æ¼”ç¤ºæ–‡ä»¶åˆ—è¡¨æ ¡éªŒåŠŸèƒ½
    invalid_file_list = [
        "/path/to/existing/file.txt",  # å‡è®¾è¿™ä¸ªæ–‡ä»¶å­˜åœ¨
        "/path/to/nonexistent/file.txt",  # ä¸å­˜åœ¨çš„æ–‡ä»¶
        "/path/to/directory",  # ç›®å½•è€Œä¸æ˜¯æ–‡ä»¶
        "",  # ç©ºå­—ç¬¦ä¸²
        123,  # éå­—ç¬¦ä¸²ç±»å‹
        "/path/to/empty/file.txt"  # å‡è®¾è¿™ä¸ªæ–‡ä»¶å¤§å°ä¸º0
    ]
    
    result3 = uploader.batch_upload(
        file_list=invalid_file_list,
        target_directory="suibian/test",
        show_progress=False
    )
    
    print("\n" + "=" * 60)
    print("â­ï¸ ç¤ºä¾‹4: è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶")
    print("=" * 60)
    
    # ç¤ºä¾‹4: æ¼”ç¤ºè·³è¿‡å·²å­˜åœ¨æ–‡ä»¶çš„åŠŸèƒ½
    existing_files = [
        "/path/to/existing/file1.txt",  # å‡è®¾è¿™ä¸ªæ–‡ä»¶åœ¨è¿œç¨‹å·²å­˜åœ¨
        "/path/to/new/file2.txt",       # å‡è®¾è¿™ä¸ªæ–‡ä»¶åœ¨è¿œç¨‹ä¸å­˜åœ¨
        "/path/to/existing/file3.csv"   # å‡è®¾è¿™ä¸ªæ–‡ä»¶åœ¨è¿œç¨‹å·²å­˜åœ¨
    ]
    
    result4 = uploader.batch_upload(
        file_list=existing_files,
        target_directory="suibian/skip_exist",
        skip_exist=True,  # å¯ç”¨è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶åŠŸèƒ½
        show_progress=False,
        verify_method="md5"  # ä½¿ç”¨MD5éªŒè¯
    )
    
    print("\n" + "=" * 60)
    print("ğŸ” ç¤ºä¾‹5: ä¸åŒéªŒè¯æ–¹æ³•æ¼”ç¤º")
    print("=" * 60)
    
    # ç¤ºä¾‹5: æ¼”ç¤ºä¸åŒçš„éªŒè¯æ–¹æ³•
    test_files = [
        "/path/to/file1.txt",
        "/path/to/file2.csv"
    ]
    
    # ä½¿ç”¨å¤§å°éªŒè¯ï¼ˆæœ€å¿«ä½†ä¸å¤Ÿå®‰å…¨ï¼‰
    result5a = uploader.batch_upload(
        file_list=test_files,
        target_directory="suibian/verify_size",
        skip_exist=True,
        show_progress=False,
        verify_method="size"
    )
    
    # ä½¿ç”¨SHA256éªŒè¯ï¼ˆæœ€å®‰å…¨ä½†è¾ƒæ…¢ï¼‰
    result5b = uploader.batch_upload(
        file_list=test_files,
        target_directory="suibian/verify_sha256",
        skip_exist=True,
        show_progress=False,
        verify_method="sha256"
    )
    
    # ä½¿ç”¨ä¸¥æ ¼éªŒè¯ï¼ˆåŒæ—¶éªŒè¯MD5å’ŒSHA256ï¼‰
    result5c = uploader.batch_upload(
        file_list=test_files,
        target_directory="suibian/verify_strict",
        skip_exist=True,
        show_progress=False,
        verify_method="strict"
    )

    
    # å¤„ç†è¿”å›ç»“æœ
    def print_result(result, example_name):
        print(f"\nğŸ“Š {example_name} ç»“æœ:")
        if result.is_success():
            print(f"âœ… ä¸Šä¼ æˆåŠŸ: {result.msg}")
            data = result.data
            print(f"   ä¸Šä¼ ä»»åŠ¡ID: {data['upload_task_id']}")
            print(f"   æˆåŠŸæ–‡ä»¶æ•°: {data['success_count']}")
            if data.get('skipped_count', 0) > 0:
                print(f"   è·³è¿‡æ–‡ä»¶æ•°: {data['skipped_count']}")
                print(f"   è·³è¿‡æ–‡ä»¶åˆ—è¡¨: {data['skipped_files']}")
            print(f"   æ€»æ–‡ä»¶å¤§å°: {data['total_size_mb']:.2f}MB")
            print(f"   æ¥æºç±»å‹: {data['source_type']}")
            if data['source_type'] == 'directory':
                print(f"   æºç›®å½•: {data['source_directory']}")
            else:
                print(f"   æºæ–‡ä»¶åˆ—è¡¨: {data['source_file_list']}")
        else:
            print(f"âŒ ä¸Šä¼ å¤±è´¥: {result.msg}")
            if result.code == ResultCode.PARAM_ERROR:
                print("   é”™è¯¯ç±»å‹: å‚æ•°é”™è¯¯")
            elif result.code == ResultCode.NOT_FOUND:
                print("   é”™è¯¯ç±»å‹: èµ„æºæœªæ‰¾åˆ°")
            elif result.code == ResultCode.CONFLICT:
                print("   é”™è¯¯ç±»å‹: èµ„æºå†²çª")
            elif result.code == ResultCode.UPLOAD_CANCELLED:
                print("   é”™è¯¯ç±»å‹: ç”¨æˆ·å–æ¶ˆ")
            elif result.code == ResultCode.SYSTEM_ERROR:
                print("   é”™è¯¯ç±»å‹: ç³»ç»Ÿé”™è¯¯")
                if result.data:
                    print(f"   å¤±è´¥æ–‡ä»¶æ•°: {result.data['failure_count']}")
                    print(f"   å¤±è´¥æ–‡ä»¶åˆ—è¡¨: {result.data['failure_files']}")
                    if result.data.get('skipped_count', 0) > 0:
                        print(f"   è·³è¿‡æ–‡ä»¶æ•°: {result.data['skipped_count']}")
                        print(f"   è·³è¿‡æ–‡ä»¶åˆ—è¡¨: {result.data['skipped_files']}")
    
    # æ‰“å°æ‰€æœ‰ç¤ºä¾‹çš„ç»“æœ
    print_result(result1, "ç›®å½•ä¸Šä¼ ")
    print_result(result2, "æ–‡ä»¶åˆ—è¡¨ä¸Šä¼ ")
    print_result(result3, "æ–‡ä»¶åˆ—è¡¨æ ¡éªŒ")
    print_result(result4, "è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶")
    print_result(result5a, "å¤§å°éªŒè¯")
    print_result(result5b, "SHA256éªŒè¯")
    print_result(result5c, "ä¸¥æ ¼éªŒè¯")

def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹ï¼šå±•ç¤ºå¦‚ä½•è°ƒç”¨ä¼˜åŒ–åçš„batch_uploadå‡½æ•°"""
    
    # åˆ›å»ºä¸Šä¼ å™¨å®ä¾‹
    uploader = BaaiRobotDataUploader(use_direct_auth=False)
    # è®¾ç½®è®¤è¯ä¿¡æ¯
    token = "eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJsaXV4dSIsImxvZ2luX3VzZXJfa2V5IjoiNjA4YjIyMjctNWYyOS00YTdkLTliNGQtZmJjNTNkY2I0YWQxIn0.NT00DxqjCNuIPavgGXworBz6qXWO70r75Mlnrk-amBiHFV0fdqZsj2Gvrg5gWK81ArYPShwDCQe8uWjlGDyRzw"
    uploader.set_eai_token(eai_token=token)
    uploader.set_max_worker(4)
    if uploader.get_ks3_sts():
    
        print("\n" + "=" * 60)
        print("ğŸ” ç¤ºä¾‹5: ä¸åŒéªŒè¯æ–¹æ³•æ¼”ç¤º")
        print("=" * 60)
        
        # ç¤ºä¾‹5: æ¼”ç¤ºä¸åŒçš„éªŒè¯æ–¹æ³•
        test_files = [
            "/Users/catkinliu/Desktop/æ•°æ®/é¸¡è›‹/episode_4.hdf5",
            # "/Users/catkinliu/Desktop/æ•°æ®/episode0.zip"
        ]
        
        # ä½¿ç”¨å¤§å°éªŒè¯ï¼ˆæœ€å¿«ä½†ä¸å¤Ÿå®‰å…¨ï¼‰
        result5a = uploader.batch_upload(
            file_list=test_files,
            target_directory="suibian/verify_size",
            skip_exist=True
        )
    
    
    

def get_result_code_meaning(code: int) -> str:
    """è·å–è¿”å›ç çš„å«ä¹‰è¯´æ˜
    
    Args:
        code: è¿”å›ç 
        
    Returns:
        str: è¿”å›ç çš„å«ä¹‰è¯´æ˜
    """
    code_meanings = {
        ResultCode.SUCCESS: "æ“ä½œæˆåŠŸ",
        ResultCode.FAIL: "æ“ä½œå¤±è´¥",
        ResultCode.PARAM_ERROR: "å‚æ•°é”™è¯¯ - è¾“å…¥å‚æ•°ä¸ç¬¦åˆè¦æ±‚",
        ResultCode.NOT_FOUND: "èµ„æºæœªæ‰¾åˆ° - æŒ‡å®šçš„è·¯å¾„æˆ–èµ„æºä¸å­˜åœ¨",
        ResultCode.UNAUTHORIZED: "æœªæˆæƒ - ç¼ºå°‘æœ‰æ•ˆçš„è®¤è¯ä¿¡æ¯",
        ResultCode.FORBIDDEN: "ç¦æ­¢è®¿é—® - æ²¡æœ‰æƒé™è®¿é—®æŒ‡å®šèµ„æº",
        ResultCode.CONFLICT: "èµ„æºå†²çª - ç›®æ ‡è·¯å¾„å·²å­˜åœ¨ï¼Œéœ€è¦é‡å‘½å",
        ResultCode.VALIDATION_ERROR: "éªŒè¯é”™è¯¯ - æ•°æ®éªŒè¯å¤±è´¥",
        ResultCode.SYSTEM_ERROR: "ç³»ç»Ÿé”™è¯¯ - ç³»ç»Ÿå†…éƒ¨é”™è¯¯æˆ–ç½‘ç»œé—®é¢˜",
        ResultCode.UPLOAD_CANCELLED: "ä¸Šä¼ è¢«å–æ¶ˆ - ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆæ“ä½œ"
    }
    return code_meanings.get(code, f"æœªçŸ¥è¿”å›ç : {code}")

if __name__ == "__main__":
    # æ˜¾ç¤ºè¿”å›ç è¯´æ˜
    print("ğŸ“‹ è¿”å›ç è¯´æ˜:")
    for code in [ResultCode.SUCCESS, ResultCode.PARAM_ERROR, ResultCode.NOT_FOUND, 
                 ResultCode.CONFLICT, ResultCode.SYSTEM_ERROR, ResultCode.UPLOAD_CANCELLED]:
        print(f"   {code}: {get_result_code_meaning(code)}")
    print()
    
    # è¿è¡Œä½¿ç”¨ç¤ºä¾‹
    example_usage()